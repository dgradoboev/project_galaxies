{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import astropy\n",
    "from astropy.coordinates import solar_system_ephemeris, EarthLocation\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import constants as const\n",
    "import hdbscan\n",
    "from astropy.io import fits\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "GrID = pd.read_csv('rcsed_iGrID.csv')\n",
    "NANfilter = pd.notna(GrID.iGrID)\n",
    "y = GrID[NANfilter]\n",
    "DATA = pd.read_csv('real_data.csv', index_col='Unnamed: 0')\n",
    "x = DATA[NANfilter]\n",
    "x = x.drop(['ind', 'spid_lamost', 'z_err', 'specObjID_sdss', 'z_sdss', 'f_spec_lega_c', 'f_z_lega_c', 'phot_data_new_galex', 'bestObjID_sdss', 'specid_6df', 'q_z_2df', 'recno_uzc', 'OBJNO_deep2', 'OBJNO_deep3', 'obsid_lamost', 'lmjd_lamost', 'mjd_lamost', 'quality_6df', 'Q_wigglez', 'NQ_gama', 'fibermag_i_sdss', 'fibermag_z_sdss', 'fibermagerr_i_sdss', 'fibermagerr_z_sdss', 'fiber2mag_i_sdss', 'fiber2mag_z_sdss', 'fiber2magerr_i_sdss', 'fiber2magerr_z_sdss', 'petromag_i_sdss', 'petromag_z_sdss', 'petromagerr_i_sdss', 'petromagerr_z_sdss', 'petror50_u_sdss', 'petror50_g_sdss', 'petror50_r_sdss', 'petror50_i_sdss', 'petror50_z_sdss' , 'multiple_z', 'dz', 'wigglez_photo'], axis=1)\n",
    "x = x.drop(x.columns[x.isna().any().values].values, axis=1)\n",
    "x = x.select_dtypes(include='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.drop([\"plate_sdss\", \"mjd_sdss\", \"fiberID_sdss\", \"fiberid_lamost\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'reset_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-acbb77701e38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'reset_index'"
     ]
    }
   ],
   "source": [
    "x = x.reset_index(drop=True)\n",
    "y = y.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.76854312, -1.22562969, -0.20610424, ...,  0.09783831,\n",
       "         0.0143573 ,  0.36430353],\n",
       "       [-2.76854266, -1.23700874, -0.26048026, ..., -0.0622559 ,\n",
       "        -0.02968761,  0.76943537],\n",
       "       [-2.76853047, -0.17891901,  2.20195971, ...,  0.33816764,\n",
       "         0.21332888,  0.11459488],\n",
       "       ...,\n",
       "       [ 2.61864792, -0.43299921,  0.66577757, ..., -0.01650083,\n",
       "        -0.00793866,  0.79173905],\n",
       "       [ 2.61866992, -1.25144744, -0.01599225, ...,  0.09131227,\n",
       "         0.01297885,  1.01963995],\n",
       "       [ 2.61868219, -1.86083405, -0.03283774, ..., -0.04332068,\n",
       "        -0.04487614,  1.00003347]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "nrmlzr = StandardScaler()\n",
    "x = nrmlzr.fit_transform(x)\n",
    "display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iGrID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>50126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>129111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>212738.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>51045.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>203801.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>50126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>214159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>50126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>22930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>50752.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>210798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>49823.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>50126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>129796.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>20789.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>24863.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>53176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>21053.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>222887.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>50126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>129682.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>205187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>205187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>50126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>218743.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>50126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>200408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>225533.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>218533.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>220035.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4104897</th>\n",
       "      <td>198335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4104958</th>\n",
       "      <td>27360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4104981</th>\n",
       "      <td>22402.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105000</th>\n",
       "      <td>50126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105020</th>\n",
       "      <td>46292.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105026</th>\n",
       "      <td>208610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105036</th>\n",
       "      <td>50126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105038</th>\n",
       "      <td>50126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105100</th>\n",
       "      <td>50126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105121</th>\n",
       "      <td>131270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105168</th>\n",
       "      <td>49074.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105172</th>\n",
       "      <td>20955.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105186</th>\n",
       "      <td>22089.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105199</th>\n",
       "      <td>46119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105228</th>\n",
       "      <td>130002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105270</th>\n",
       "      <td>50126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105279</th>\n",
       "      <td>26562.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105293</th>\n",
       "      <td>127960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105320</th>\n",
       "      <td>212341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105337</th>\n",
       "      <td>50126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105352</th>\n",
       "      <td>226453.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105363</th>\n",
       "      <td>24236.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105376</th>\n",
       "      <td>226454.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105404</th>\n",
       "      <td>50126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105425</th>\n",
       "      <td>24863.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105450</th>\n",
       "      <td>22043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105454</th>\n",
       "      <td>50126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105456</th>\n",
       "      <td>22392.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105477</th>\n",
       "      <td>164105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105488</th>\n",
       "      <td>23545.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401148 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            iGrID\n",
       "59        50126.0\n",
       "62       129111.0\n",
       "72       212738.0\n",
       "92        51045.0\n",
       "99       203801.0\n",
       "101       50126.0\n",
       "103      214159.0\n",
       "108       50126.0\n",
       "116       22930.0\n",
       "123       50752.0\n",
       "144      210798.0\n",
       "175       49823.0\n",
       "190       50126.0\n",
       "210      129796.0\n",
       "220       20789.0\n",
       "276       24863.0\n",
       "286       53176.0\n",
       "300       21053.0\n",
       "303      222887.0\n",
       "305       50126.0\n",
       "357      129682.0\n",
       "358      205187.0\n",
       "393      205187.0\n",
       "439       50126.0\n",
       "441      218743.0\n",
       "470       50126.0\n",
       "474      200408.0\n",
       "475      225533.0\n",
       "479      218533.0\n",
       "499      220035.0\n",
       "...           ...\n",
       "4104897  198335.0\n",
       "4104958   27360.0\n",
       "4104981   22402.0\n",
       "4105000   50126.0\n",
       "4105020   46292.0\n",
       "4105026  208610.0\n",
       "4105036   50126.0\n",
       "4105038   50126.0\n",
       "4105100   50126.0\n",
       "4105121  131270.0\n",
       "4105168   49074.0\n",
       "4105172   20955.0\n",
       "4105186   22089.0\n",
       "4105199   46119.0\n",
       "4105228  130002.0\n",
       "4105270   50126.0\n",
       "4105279   26562.0\n",
       "4105293  127960.0\n",
       "4105320  212341.0\n",
       "4105337   50126.0\n",
       "4105352  226453.0\n",
       "4105363   24236.0\n",
       "4105376  226454.0\n",
       "4105404   50126.0\n",
       "4105425   24863.0\n",
       "4105450   22043.0\n",
       "4105454   50126.0\n",
       "4105456   22392.0\n",
       "4105477  164105.0\n",
       "4105488   23545.0\n",
       "\n",
       "[401148 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401148, 62)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
    "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
    "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
    "\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim2)\n",
    "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
    "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return self.fc31(h), self.fc32(h)\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu)\n",
    "        \n",
    "    def decoder(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        h = F.relu(self.fc5(h))\n",
    "        return torch.sigmoid(self.fc6(h)) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x.view(-1, 62))\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(x_dim=62, h_dim1= 45, h_dim2=30, z_dim=7)\n",
    "if torch.cuda.is_available():\n",
    "    vae.cuda()\n",
    "\n",
    "optimizer = optim.Adam(vae.parameters())\n",
    "train_loader = torch.utils.data.DataLoader(dataset=x, batch_size=1000, shuffle=True)\n",
    "\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    criterion = nn.MSELoss().cuda()\n",
    "    BCE = criterion(recon_x, x.view(-1, 62))\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "def train(epoch):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx in range(400):\n",
    "        #data = torch.tensor(x.sample(n=1000).astype(np.float32).values)\n",
    "        data = torch.tensor(x[np.random.choice(range(x.shape[0]), 1000)].astype(np.float32))\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, log_var = vae(data)\n",
    "        loss = loss_function(recon_batch, data, mu, log_var)\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/401148 (0%)]\tLoss: 0.092240\n",
      "Train Epoch: 1 [100000/401148 (25%)]\tLoss: 0.002868\n",
      "Train Epoch: 1 [200000/401148 (50%)]\tLoss: 0.002187\n",
      "Train Epoch: 1 [300000/401148 (75%)]\tLoss: 0.000998\n",
      "====> Epoch: 1 Average loss: 0.5989\n",
      "Train Epoch: 2 [0/401148 (0%)]\tLoss: 0.001626\n",
      "Train Epoch: 2 [100000/401148 (25%)]\tLoss: 0.001078\n",
      "Train Epoch: 2 [200000/401148 (50%)]\tLoss: 0.000785\n",
      "Train Epoch: 2 [300000/401148 (75%)]\tLoss: 0.001171\n",
      "====> Epoch: 2 Average loss: 0.0015\n",
      "Train Epoch: 3 [0/401148 (0%)]\tLoss: 0.002339\n",
      "Train Epoch: 3 [100000/401148 (25%)]\tLoss: 0.000746\n",
      "Train Epoch: 3 [200000/401148 (50%)]\tLoss: 0.000677\n",
      "Train Epoch: 3 [300000/401148 (75%)]\tLoss: 0.000733\n",
      "====> Epoch: 3 Average loss: 0.0011\n",
      "Train Epoch: 4 [0/401148 (0%)]\tLoss: 0.000911\n",
      "Train Epoch: 4 [100000/401148 (25%)]\tLoss: 0.000656\n",
      "Train Epoch: 4 [200000/401148 (50%)]\tLoss: 0.001092\n",
      "Train Epoch: 4 [300000/401148 (75%)]\tLoss: 0.000773\n",
      "====> Epoch: 4 Average loss: 0.0011\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 5):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, log_var = vae.encoder(torch.tensor(x.astype(np.float32)))\n",
    "embed = vae.sampling(mu, log_var).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16447295, -0.88133496,  1.0313933 , ..., -0.33865055,\n",
       "        -0.17480463, -0.5728178 ],\n",
       "       [ 1.0925106 ,  0.19881423,  0.02260388, ...,  0.02729067,\n",
       "         1.4517192 ,  0.31191292],\n",
       "       [ 1.8581895 , -1.5041358 ,  0.8280001 , ...,  0.4780128 ,\n",
       "        -0.89910483, -0.3174661 ],\n",
       "       ...,\n",
       "       [-2.2284477 , -0.5752071 ,  0.2339124 , ..., -0.15768902,\n",
       "         2.0764897 , -0.6929708 ],\n",
       "       [ 1.3544052 ,  0.18003255, -0.61603814, ..., -0.5695588 ,\n",
       "         1.920867  ,  0.7287321 ],\n",
       "       [-1.7260247 , -0.703662  ,  0.45988968, ...,  0.23031314,\n",
       "        -1.9716207 , -0.5583463 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbScan = hdbscan.HDBSCAN(allow_single_cluster=True, min_samples=1).fit(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0024752949749627675, 0.7463225981915803, 0.00493422482585403)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homogeneity_completeness_v_measure(y.iGrID, hdbScan.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f4b29c93cd4e50b1be33cbce3bf602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "gridRes = []\n",
    "for alpha in tqdm(np.linspace(0.1, 3, 7)):\n",
    "        hdbScan = hdbscan.HDBSCAN(min_samples=1, alpha=alpha, allow_single_cluster=True).fit(embed)\n",
    "        gridRes.append((homogeneity_completeness_v_measure(y.iGrID, hdbScan.labels_), calinski_harabasz_score(embed, hdbScan.labels_), [alpha]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((0.0024752949749627675, 0.7463225981915803, 0.00493422482585403), 1.8672345153667382, [0.1]), ((0.0024752949749627675, 0.7463225981915803, 0.00493422482585403), 1.8672345153667382, [0.5833333333333334]), ((0.0024752949749627675, 0.7463225981915803, 0.00493422482585403), 1.8672345153667382, [1.0666666666666667]), ((0.0024752949749627675, 0.7463225981915803, 0.00493422482585403), 1.8672345153667382, [1.55]), ((0.0024752949749627675, 0.7463225981915803, 0.00493422482585403), 1.8672345153667382, [2.033333333333333]), ((0.0024752949749627675, 0.7463225981915803, 0.00493422482585403), 1.8672345153667382, [2.5166666666666666]), ((0.0024752949749627675, 0.7463225981915803, 0.00493422482585403), 1.8672345153667382, [3.0])]\n"
     ]
    }
   ],
   "source": [
    "print(gridRes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc41442e04c242eb971e67336802da5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "gridRes = []\n",
    "for alpha in tqdm(np.linspace(1e-7, 1e-2, 6)):\n",
    "        hdbScan = hdbscan.HDBSCAN(min_samples=1, alpha=alpha, allow_single_cluster=True).fit(embed)\n",
    "        gridRes.append((homogeneity_completeness_v_measure(y.iGrID, hdbScan.labels_), calinski_harabasz_score(embed, hdbScan.labels_), [alpha]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((0.0024752949749627675, 0.7463225981915803, 0.00493422482585403), 1.8672345153667382, [1e-07]), ((0.0024752949749627675, 0.7463225981915803, 0.00493422482585403), 1.8672345153667382, [0.00200008]), ((0.0024752949749627675, 0.7463225981915803, 0.00493422482585403), 1.8672345153667382, [0.004000060000000001]), ((0.0024752949749627675, 0.7463225981915803, 0.00493422482585403), 1.8672345153667382, [0.006000040000000001]), ((0.0024752949749627675, 0.7463225981915803, 0.00493422482585403), 1.8672345153667382, [0.00800002]), ((0.0024752949749627675, 0.7463225981915803, 0.00493422482585403), 1.8672345153667382, [0.01])]\n"
     ]
    }
   ],
   "source": [
    "print(gridRes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/401148 (0%)]\tLoss: 0.107453\n",
      "Train Epoch: 1 [100000/401148 (25%)]\tLoss: 0.003787\n",
      "Train Epoch: 1 [200000/401148 (50%)]\tLoss: 0.001813\n",
      "Train Epoch: 1 [300000/401148 (75%)]\tLoss: 0.000800\n",
      "====> Epoch: 1 Average loss: 0.0069\n",
      "Train Epoch: 2 [0/401148 (0%)]\tLoss: 0.000782\n",
      "Train Epoch: 2 [100000/401148 (25%)]\tLoss: 0.000763\n",
      "Train Epoch: 2 [200000/401148 (50%)]\tLoss: 0.000652\n",
      "Train Epoch: 2 [300000/401148 (75%)]\tLoss: 0.000713\n",
      "====> Epoch: 2 Average loss: 0.0013\n",
      "Train Epoch: 3 [0/401148 (0%)]\tLoss: 0.000866\n",
      "Train Epoch: 3 [100000/401148 (25%)]\tLoss: 0.001793\n",
      "Train Epoch: 3 [200000/401148 (50%)]\tLoss: 0.000770\n",
      "Train Epoch: 3 [300000/401148 (75%)]\tLoss: 0.001055\n",
      "====> Epoch: 3 Average loss: 0.0013\n",
      "Train Epoch: 4 [0/401148 (0%)]\tLoss: 0.000745\n",
      "Train Epoch: 4 [100000/401148 (25%)]\tLoss: 0.002262\n",
      "Train Epoch: 4 [200000/401148 (50%)]\tLoss: 0.000606\n",
      "Train Epoch: 4 [300000/401148 (75%)]\tLoss: 0.000627\n",
      "====> Epoch: 4 Average loss: 0.0014\n",
      "Train Epoch: 5 [0/401148 (0%)]\tLoss: 0.002092\n",
      "Train Epoch: 5 [100000/401148 (25%)]\tLoss: 0.000980\n",
      "Train Epoch: 5 [200000/401148 (50%)]\tLoss: 0.000697\n",
      "Train Epoch: 5 [300000/401148 (75%)]\tLoss: 0.000632\n",
      "====> Epoch: 5 Average loss: 0.0052\n",
      "Train Epoch: 6 [0/401148 (0%)]\tLoss: 0.001159\n",
      "Train Epoch: 6 [100000/401148 (25%)]\tLoss: 0.000695\n",
      "Train Epoch: 6 [200000/401148 (50%)]\tLoss: 0.000656\n",
      "Train Epoch: 6 [300000/401148 (75%)]\tLoss: 0.000617\n",
      "====> Epoch: 6 Average loss: 0.0010\n",
      "Train Epoch: 7 [0/401148 (0%)]\tLoss: 0.000882\n",
      "Train Epoch: 7 [100000/401148 (25%)]\tLoss: 0.000954\n",
      "Train Epoch: 7 [200000/401148 (50%)]\tLoss: 0.000543\n",
      "Train Epoch: 7 [300000/401148 (75%)]\tLoss: 0.000677\n",
      "====> Epoch: 7 Average loss: 0.0011\n",
      "Train Epoch: 8 [0/401148 (0%)]\tLoss: 0.000644\n",
      "Train Epoch: 8 [100000/401148 (25%)]\tLoss: 0.002054\n",
      "Train Epoch: 8 [200000/401148 (50%)]\tLoss: 0.000727\n",
      "Train Epoch: 8 [300000/401148 (75%)]\tLoss: 0.000739\n",
      "====> Epoch: 8 Average loss: 0.0010\n",
      "Train Epoch: 9 [0/401148 (0%)]\tLoss: 0.000588\n",
      "Train Epoch: 9 [100000/401148 (25%)]\tLoss: 0.000631\n",
      "Train Epoch: 9 [200000/401148 (50%)]\tLoss: 0.000636\n",
      "Train Epoch: 9 [300000/401148 (75%)]\tLoss: 0.000499\n",
      "====> Epoch: 9 Average loss: 0.0010\n",
      "Train Epoch: 10 [0/401148 (0%)]\tLoss: 0.001001\n",
      "Train Epoch: 10 [100000/401148 (25%)]\tLoss: 0.000634\n",
      "Train Epoch: 10 [200000/401148 (50%)]\tLoss: 0.000706\n",
      "Train Epoch: 10 [300000/401148 (75%)]\tLoss: 0.000552\n",
      "====> Epoch: 10 Average loss: 0.0010\n",
      "Train Epoch: 11 [0/401148 (0%)]\tLoss: 0.000584\n",
      "Train Epoch: 11 [100000/401148 (25%)]\tLoss: 0.000691\n",
      "Train Epoch: 11 [200000/401148 (50%)]\tLoss: 0.000750\n",
      "Train Epoch: 11 [300000/401148 (75%)]\tLoss: 0.000650\n",
      "====> Epoch: 11 Average loss: 0.0010\n",
      "Train Epoch: 12 [0/401148 (0%)]\tLoss: 0.000541\n",
      "Train Epoch: 12 [100000/401148 (25%)]\tLoss: 0.000733\n",
      "Train Epoch: 12 [200000/401148 (50%)]\tLoss: 0.001649\n",
      "Train Epoch: 12 [300000/401148 (75%)]\tLoss: 0.000656\n",
      "====> Epoch: 12 Average loss: 0.0010\n",
      "Train Epoch: 13 [0/401148 (0%)]\tLoss: 0.000866\n",
      "Train Epoch: 13 [100000/401148 (25%)]\tLoss: 0.001115\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-638a6b2a41c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-22f3402f5f63>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m#data = torch.tensor(x.sample(n=1000).astype(np.float32).values)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[1;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[0;32m   2769\u001b[0m     \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2770\u001b[0m     \"\"\"\n\u001b[1;32m-> 2771\u001b[1;33m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[0;32m   2772\u001b[0m                           initial=initial)\n\u001b[0;32m   2773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vae = VAE(x_dim=62, h_dim1= 45, h_dim2=30, z_dim=7)\n",
    "if torch.cuda.is_available():\n",
    "    vae.cuda()\n",
    "\n",
    "optimizer = optim.Adam(vae.parameters())\n",
    "train_loader = torch.utils.data.DataLoader(dataset=x, batch_size=1000, shuffle=True)\n",
    "\n",
    "for epoch in range(1, 30):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
